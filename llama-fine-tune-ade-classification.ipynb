{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9731785,"sourceType":"datasetVersion","datasetId":5955564}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-29T02:59:58.467538Z","iopub.execute_input":"2024-10-29T02:59:58.467865Z","iopub.status.idle":"2024-10-29T02:59:59.512469Z","shell.execute_reply.started":"2024-10-29T02:59:58.467828Z","shell.execute_reply":"2024-10-29T02:59:59.511224Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/list11/filtered_conditions.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q transformers accelerate trl bitsandbytes datasets evaluate \n!pip install -q peft scikit-learn\n# pip install huggingface-cli ","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:02:16.158247Z","iopub.execute_input":"2024-10-29T03:02:16.158701Z","iopub.status.idle":"2024-10-29T03:02:47.578056Z","shell.execute_reply.started":"2024-10-29T03:02:16.158656Z","shell.execute_reply":"2024-10-29T03:02:47.576819Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!huggingface-cli login --token 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 ","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:01:47.229762Z","iopub.execute_input":"2024-10-29T03:01:47.230194Z","iopub.status.idle":"2024-10-29T03:01:48.883624Z","shell.execute_reply.started":"2024-10-29T03:01:47.230149Z","shell.execute_reply":"2024-10-29T03:01:48.882389Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install datasets","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:04:06.818628Z","iopub.execute_input":"2024-10-29T03:04:06.819686Z","iopub.status.idle":"2024-10-29T03:04:19.517862Z","shell.execute_reply.started":"2024-10-29T03:04:06.819639Z","shell.execute_reply":"2024-10-29T03:04:19.516815Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"split_data = dataset[\"train\"].train_test_split()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:07:27.432736Z","iopub.execute_input":"2024-10-29T03:07:27.433444Z","iopub.status.idle":"2024-10-29T03:07:27.463228Z","shell.execute_reply.started":"2024-10-29T03:07:27.433400Z","shell.execute_reply":"2024-10-29T03:07:27.462230Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"ade_corpus_v2\",\"Ade_corpus_v2_classification\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:05:16.353404Z","iopub.execute_input":"2024-10-29T03:05:16.353803Z","iopub.status.idle":"2024-10-29T03:05:21.382831Z","shell.execute_reply.started":"2024-10-29T03:05:16.353762Z","shell.execute_reply":"2024-10-29T03:05:21.381982Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74162fb216ac4dc69d8e4d1989931aee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/1.71M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07eebe9c34fb46d08a57750ed0910f0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/23516 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21823df7d11b452f92d8fc7208f08fa0"}},"metadata":{}}]},{"cell_type":"code","source":"train_data = split_data[\"train\"]\ntest_data = split_data[\"test\"]","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:08:05.683296Z","iopub.execute_input":"2024-10-29T03:08:05.683759Z","iopub.status.idle":"2024-10-29T03:08:05.688743Z","shell.execute_reply.started":"2024-10-29T03:08:05.683721Z","shell.execute_reply":"2024-10-29T03:08:05.687599Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:08:12.083511Z","iopub.execute_input":"2024-10-29T03:08:12.084233Z","iopub.status.idle":"2024-10-29T03:08:12.090680Z","shell.execute_reply.started":"2024-10-29T03:08:12.084192Z","shell.execute_reply":"2024-10-29T03:08:12.089587Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'label'],\n    num_rows: 17637\n})"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(train_data)\n\ndf.label.value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:08:43.238930Z","iopub.execute_input":"2024-10-29T03:08:43.239385Z","iopub.status.idle":"2024-10-29T03:08:44.684020Z","shell.execute_reply.started":"2024-10-29T03:08:43.239304Z","shell.execute_reply":"2024-10-29T03:08:44.682969Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"label\n0    0.709871\n1    0.290129\nName: proportion, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"label_1_df = df[df['label'] == 0]\nlabel_2_df = df[df['label'] == 1]","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:09:32.602690Z","iopub.execute_input":"2024-10-29T03:09:32.603618Z","iopub.status.idle":"2024-10-29T03:09:32.614824Z","shell.execute_reply.started":"2024-10-29T03:09:32.603575Z","shell.execute_reply":"2024-10-29T03:09:32.613879Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Shuffle each label dataframe\nlabel_1_df = label_1_df.sample(frac=1).reset_index(drop=True)\nlabel_2_df = label_2_df.sample(frac=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:09:47.173516Z","iopub.execute_input":"2024-10-29T03:09:47.174221Z","iopub.status.idle":"2024-10-29T03:09:47.184991Z","shell.execute_reply.started":"2024-10-29T03:09:47.174168Z","shell.execute_reply":"2024-10-29T03:09:47.184074Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Splitting each label dataframe into train, test, and validation sets\nlabel_1_train = label_1_df.iloc[:2000]\nlabel_1_test = label_1_df.iloc[2000:2500]\nlabel_1_val = label_1_df.iloc[2500:3000]\n\nlabel_2_train = label_2_df.iloc[:2000]\nlabel_2_test = label_2_df.iloc[2000:2500]\nlabel_2_val = label_2_df.iloc[2500:3000]","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:10:32.873517Z","iopub.execute_input":"2024-10-29T03:10:32.873949Z","iopub.status.idle":"2024-10-29T03:10:32.881020Z","shell.execute_reply.started":"2024-10-29T03:10:32.873909Z","shell.execute_reply":"2024-10-29T03:10:32.879749Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Concatenating the splits back together\ntrain_df = pd.concat([label_1_train, label_2_train])\ntest_df = pd.concat([label_1_test, label_2_test])\nval_df = pd.concat([label_1_val, label_2_val])","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:11:22.743701Z","iopub.execute_input":"2024-10-29T03:11:22.744606Z","iopub.status.idle":"2024-10-29T03:11:22.751916Z","shell.execute_reply.started":"2024-10-29T03:11:22.744564Z","shell.execute_reply":"2024-10-29T03:11:22.750870Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Shuffle the dataframes to ensure randomness\ntrain_df = train_df.sample(frac=1).reset_index(drop=True)\ntest_df = test_df.sample(frac=1).reset_index(drop=True)\nval_df = val_df.sample(frac=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:11:33.653479Z","iopub.execute_input":"2024-10-29T03:11:33.653898Z","iopub.status.idle":"2024-10-29T03:11:33.662906Z","shell.execute_reply.started":"2024-10-29T03:11:33.653859Z","shell.execute_reply":"2024-10-29T03:11:33.661721Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:11:45.533580Z","iopub.execute_input":"2024-10-29T03:11:45.533969Z","iopub.status.idle":"2024-10-29T03:11:45.543126Z","shell.execute_reply.started":"2024-10-29T03:11:45.533930Z","shell.execute_reply":"2024-10-29T03:11:45.541838Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"label\n0    2000\n1    2000\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import DatasetDict, Dataset\n\n# Converting pandas DataFrames into Hugging Face Dataset objects:\ndataset_train = Dataset.from_pandas(train_df)\ndataset_val = Dataset.from_pandas(val_df)\ndataset_test = Dataset.from_pandas(test_df)\n\n# Combine them into a single DatasetDict\ndataset = DatasetDict({\n    'train': dataset_train,\n    'val': dataset_val,\n    'test': dataset_test\n})\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:12:39.883456Z","iopub.execute_input":"2024-10-29T03:12:39.883892Z","iopub.status.idle":"2024-10-29T03:12:39.917391Z","shell.execute_reply.started":"2024-10-29T03:12:39.883851Z","shell.execute_reply":"2024-10-29T03:12:39.916524Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 4000\n    })\n    val: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\nclass_weights=(1/train_df.label.value_counts(normalize=True).sort_index()).tolist()\nclass_weights=torch.tensor(class_weights)\nclass_weights=class_weights/class_weights.sum()\nclass_weights","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:13:11.943299Z","iopub.execute_input":"2024-10-29T03:13:11.943761Z","iopub.status.idle":"2024-10-29T03:13:15.580921Z","shell.execute_reply.started":"2024-10-29T03:13:11.943717Z","shell.execute_reply":"2024-10-29T03:13:15.579763Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"tensor([0.5000, 0.5000])"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig, AutoModelForSequenceClassification\n\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit = True, \n    bnb_4bit_quant_type = 'nf4',\n    bnb_4bit_use_double_quant = True, \n    bnb_4bit_compute_dtype = torch.bfloat16 \n)\n\nmodel_name = \"meta-llama/Meta-Llama-3-8B\"\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    quantization_config=quantization_config,\n    num_labels=2,\n    device_map='auto'\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:48:50.643979Z","iopub.execute_input":"2024-10-29T03:48:50.644421Z","iopub.status.idle":"2024-10-29T03:50:22.983504Z","shell.execute_reply.started":"2024-10-29T03:48:50.644380Z","shell.execute_reply":"2024-10-29T03:50:22.982665Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5670fcc382242e49a4c56449d405c6f"}},"metadata":{}},{"name":"stderr","text":"Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n\nlora_config = LoraConfig(\n    r = 16, \n    lora_alpha = 8,\n    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n    lora_dropout = 0.05, \n    bias = 'none',\n    task_type = 'SEQ_CLS'\n)\n\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:51:06.568236Z","iopub.execute_input":"2024-10-29T03:51:06.568624Z","iopub.status.idle":"2024-10-29T03:51:06.971259Z","shell.execute_reply.started":"2024-10-29T03:51:06.568590Z","shell.execute_reply":"2024-10-29T03:51:06.970375Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_name = \"meta-llama/Meta-Llama-3-8B\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n\ntokenizer.pad_token_id = tokenizer.eos_token_id\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:29:41.583705Z","iopub.execute_input":"2024-10-29T03:29:41.584600Z","iopub.status.idle":"2024-10-29T03:29:43.265424Z","shell.execute_reply.started":"2024-10-29T03:29:41.584558Z","shell.execute_reply":"2024-10-29T03:29:43.264618Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c92a92ae455440268d97a77fae1f10c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc45842de2de426dbf91ab1e74c4acfc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de63741123054a9abbad334a16607885"}},"metadata":{}}]},{"cell_type":"code","source":"model.config.pad_token_id = tokenizer.pad_token_id\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:51:23.778139Z","iopub.execute_input":"2024-10-29T03:51:23.778536Z","iopub.status.idle":"2024-10-29T03:51:23.783518Z","shell.execute_reply.started":"2024-10-29T03:51:23.778499Z","shell.execute_reply":"2024-10-29T03:51:23.782494Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"sentences = test_df.text.tolist()\n\nbatch_size = 32  \n\nall_outputs = []\n\nfor i in range(0, len(sentences), batch_size):\n    batch_sentences = sentences[i:i + batch_size]\n\n    inputs = tokenizer(batch_sentences, return_tensors=\"pt\", \n    padding=True, truncation=True, max_length=512)\n\n    inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n        all_outputs.append(outputs['logits'])\n        \nfinal_outputs = torch.cat(all_outputs, dim=0)\ntest_df['predictions']=final_outputs.argmax(axis=1).cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:51:33.563654Z","iopub.execute_input":"2024-10-29T03:51:33.564046Z","iopub.status.idle":"2024-10-29T03:56:18.101960Z","shell.execute_reply.started":"2024-10-29T03:51:33.564013Z","shell.execute_reply":"2024-10-29T03:56:18.100762Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import balanced_accuracy_score, classification_report\n\ndef get_metrics_result(test_df):\n    y_test = test_df.label\n    y_pred = test_df.predictions\n\n    print(\"Classification Report:\")\n    print(classification_report(y_test, y_pred))\n\n    print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n\nget_metrics_result(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:56:27.644016Z","iopub.execute_input":"2024-10-29T03:56:27.644934Z","iopub.status.idle":"2024-10-29T03:56:27.666297Z","shell.execute_reply.started":"2024-10-29T03:56:27.644892Z","shell.execute_reply":"2024-10-29T03:56:27.665391Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.48      0.89      0.62       500\n           1       0.27      0.04      0.07       500\n\n    accuracy                           0.47      1000\n   macro avg       0.37      0.47      0.35      1000\nweighted avg       0.37      0.47      0.35      1000\n\nBalanced Accuracy Score: 0.465\nAccuracy Score: 0.465\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_preprocesing(row):\n    return tokenizer(row['text'], truncation=True, max_length=512)\n\ntokenized_data = dataset.map(data_preprocesing, batched=True, \nremove_columns=['text'])\ntokenized_data.set_format(\"torch\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:37:33.783994Z","iopub.execute_input":"2024-10-29T03:37:33.784853Z","iopub.status.idle":"2024-10-29T03:37:34.834201Z","shell.execute_reply.started":"2024-10-29T03:37:33.784811Z","shell.execute_reply":"2024-10-29T03:37:34.833347Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9d76eff9e3a456ba74c0cbfef28fb09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d1e4ff0acc5465e94d6028499324cc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"564e7edb5ae146fe810feb5df8b83f43"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ncollate_fn = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:37:44.648637Z","iopub.execute_input":"2024-10-29T03:37:44.649029Z","iopub.status.idle":"2024-10-29T03:37:44.674677Z","shell.execute_reply.started":"2024-10-29T03:37:44.648992Z","shell.execute_reply":"2024-10-29T03:37:44.673953Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(evaluations):\n    predictions, labels = evaluations\n    predictions = np.argmax(predictions, axis=1)\n    return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),\n    'accuracy':accuracy_score(predictions,labels)}","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:57:07.353629Z","iopub.execute_input":"2024-10-29T03:57:07.354023Z","iopub.status.idle":"2024-10-29T03:57:07.362233Z","shell.execute_reply.started":"2024-10-29T03:57:07.353985Z","shell.execute_reply":"2024-10-29T03:57:07.361086Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\nimport torch\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:39:41.283941Z","iopub.execute_input":"2024-10-29T03:39:41.284720Z","iopub.status.idle":"2024-10-29T03:39:42.461390Z","shell.execute_reply.started":"2024-10-29T03:39:41.284679Z","shell.execute_reply":"2024-10-29T03:39:42.460512Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class CustomTrainer(Trainer):\n    def __init__(self, *args, class_weights=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        if class_weights is not None:\n            self.class_weights = torch.tensor(class_weights, \n            dtype=torch.float32).to(self.args.device)\n        else:\n            self.class_weights = None\n\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\").long()\n\n        outputs = model(**inputs)\n\n        logits = outputs.get('logits')\n\n        if self.class_weights is not None:\n            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n        else:\n            loss = F.cross_entropy(logits, labels)\n\n        return (loss, outputs) if return_outputs else loss","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:57:16.758371Z","iopub.execute_input":"2024-10-29T03:57:16.759134Z","iopub.status.idle":"2024-10-29T03:57:16.767876Z","shell.execute_reply.started":"2024-10-29T03:57:16.759092Z","shell.execute_reply":"2024-10-29T03:57:16.766810Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir='sentiment_classification',\n    learning_rate=1e-4,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=1,\n    logging_steps=1,\n    weight_decay=0.01,\n    evaluation_strategy='epoch',\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    report_to=\"none\"\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:57:30.853134Z","iopub.execute_input":"2024-10-29T03:57:30.853957Z","iopub.status.idle":"2024-10-29T03:57:30.888965Z","shell.execute_reply.started":"2024-10-29T03:57:30.853915Z","shell.execute_reply":"2024-10-29T03:57:30.888014Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = tokenized_data['train'],\n    eval_dataset = tokenized_data['val'],\n    tokenizer = tokenizer,\n    data_collator = collate_fn,\n    compute_metrics = compute_metrics,\n    class_weights=class_weights,\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:57:35.732726Z","iopub.execute_input":"2024-10-29T03:57:35.733571Z","iopub.status.idle":"2024-10-29T03:57:35.747475Z","shell.execute_reply.started":"2024-10-29T03:57:35.733529Z","shell.execute_reply":"2024-10-29T03:57:35.746562Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3147221490.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  self.class_weights = torch.tensor(class_weights,\n","output_type":"stream"}]},{"cell_type":"code","source":"train_result = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T03:57:39.392980Z","iopub.execute_input":"2024-10-29T03:57:39.393384Z","iopub.status.idle":"2024-10-29T04:56:54.840493Z","shell.execute_reply.started":"2024-10-29T03:57:39.393345Z","shell.execute_reply":"2024-10-29T04:56:54.839406Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [500/500 59:06, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Balanced Accuracy</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.045000</td>\n      <td>0.188366</td>\n      <td>0.950584</td>\n      <td>0.950000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\ndef get_performance_metrics(df):\n    y_true = df['label'].values  # Assuming 'label' is the column with true labels\n    y_pred = df['predictions'].values  # Assuming 'predictions' is the column with predicted labels\n\n    accuracy = accuracy_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred, average='binary')  # Change to 'macro' if you want class-wise scores\n    recall = recall_score(y_true, y_pred, average='binary')\n    f1 = f1_score(y_true, y_pred, average='binary')\n\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n\n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T05:25:54.744589Z","iopub.execute_input":"2024-10-29T05:25:54.745419Z","iopub.status.idle":"2024-10-29T05:25:54.752814Z","shell.execute_reply.started":"2024-10-29T05:25:54.745379Z","shell.execute_reply":"2024-10-29T05:25:54.751773Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"def generate_predictions(model,df_test):\n    sentences = df_test.text.tolist()\n    batch_size = 32  \n    all_outputs = []\n\n    for i in range(0, len(sentences), batch_size):\n\n        batch_sentences = sentences[i:i + batch_size]\n\n        inputs = tokenizer(batch_sentences, return_tensors=\"pt\", \n        padding=True, truncation=True, max_length=512)\n\n        inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') \n        for k, v in inputs.items()}\n\n        with torch.no_grad():\n            outputs = model(**inputs)\n            all_outputs.append(outputs['logits'])\n        \n    final_outputs = torch.cat(all_outputs, dim=0)\n    df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n\ngenerate_predictions(model,test_df)\nget_performance_metrics(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T05:25:59.913808Z","iopub.execute_input":"2024-10-29T05:25:59.914599Z","iopub.status.idle":"2024-10-29T05:30:43.872585Z","shell.execute_reply.started":"2024-10-29T05:25:59.914560Z","shell.execute_reply":"2024-10-29T05:30:43.871570Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Accuracy: 0.9260\nPrecision: 0.9004\nRecall: 0.9580\nF1 Score: 0.9283\n","output_type":"stream"},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.926,\n 'precision': 0.900375939849624,\n 'recall': 0.958,\n 'f1': 0.9282945736434108}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}